\documentclass[a4paper,11pt]{article}
\usepackage{amsmath,amssymb,amsfonts,latexsym}
\usepackage[utf8]{inputenc}
\usepackage{fancyvrb}
\usepackage{graphicx}
\usepackage[margin=1.1in]{geometry}
\usepackage{url}
\usepackage{verbatim}
\usepackage{fixltx2e}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{float}
\usepackage{listings}
\usepackage{lmodern}
\usepackage[spanish]{babel}
\lstset{frame=tb,
  language=Java,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  breaklines=true,
  breakatwhitespace=true
  tabsize=3
}
\title{Speech compression \\
M\'etodos Num\'ericos Avanzados}
\author{Enzo Altamiranda, Cristian Ontiver, Valeria Serber}
\date{\today}
\begin{document}

\maketitle
\thispagestyle{empty}
\vspace{3cm}

\renewcommand{\abstractname}{Resumen}
\begin{abstract}
El siguiente informe explora el uso de la transformada rápida de Fourier, en
combinación con la codificación de Huffman para la compresión de voz en formato
wav, en conjunto con otras técnicas como el truncado, cuantificación lineal y
\textit{thresholding}, con el fin de aumentar la eficacia de la compresión.
%Se realiza un estudio comparativo de diferentes niveles de cuantificación y sus
%efectos tanto en el tamaño como la calidad - en términos de distorción - del
%archivo comprimido.
\\[5pt]
\noindent \textbf{Keywords.} Transformada Rápida de Fourier, Compresión de voz, Codificación de Huffman
\end{abstract}
\newpage
\section{Introducci\'on}
\begin{comment}
[Introduce el tema contextualizando la informacion. Puede incluirse un parrafo
con una breve descripcion historica, otro parrafo motivando el tema. El ultimo
parrafo de esta seccion tiene que ser la descripcion de la estructura del
artıculo, explicitando en que seccion se trata cada tema.]
\end{comment}
La voz, entendida como el sonido generado por el aparato fonador humano, se
encuentra en frencuencias de entre $80$ a $1100$ Hz.  Teniendo esto en cuenta,
a la hora de almacenar digitalmente una señal de voz, es posible utilizar
métodos para reducir el tamaño necesario para guardar la información
correspondiente a esta señal.\\
Tradicionalmente estos se dividen en dos. Por un lado métodos ``lossless'' (sin
pérdida), es decir, métodos que almacenan la información de modo tal que esta
pueda ser recuperada en su totalidad. Por otro, métodos ``lossy'' (con pérdida),
en los cuales, tomando ventaja de que el rango de audición humano suele
situarse entre los $20$ y $20.000$ Hz (con variaciones de individuo a
individuo), descartan información considerada redundante (aquella por encima o
por debajo de ese rango).\\
Aquí exploramos una forma de lograr lo segundo, mediante el uso de la
transformada rápida de Fourier, en conjunto con la codificación de Huffman,
para lograr almacenar diferentes archivos de sonidos conteniendo voces, de
manera que se reduzca el tamaño necesario.\\
En primer lugar, se explica la metodología seguida, desde la grabación
inicial de las diferentes pruebas, pasando por las diferentes etapas hasta
llegar a la versión comprimida, y luego el camino inverso para descomprimir el
archivo generado y poder reproducirlo.
Seguido de esto, se presentan los resultados obtenidos, realizando una
comparación entre los archivos originales y sus correspondientes pares
comprimidos, además de análisis sobre el efecto de varias ciertas variables del
problema en cuestión.
Por último, se describen las conclusiones obtenidas.

%Como se verá más adelante, una reducción
%en la distorición y aumento en la fidelidad del audio comprimido implican la
%necesidad de mayor información, y por ende, una menor reducción en relación al
%tamaño (en bytes) original.
\section{Metodolog\'ia}
\begin{comment}
[Hay que relatar los pasos que se fueron realizando, incluyendo los modelos
utilizados, los analisis hechos, las pruebas realizadas.]
\end{comment}
\subsection{Grabación de voz}
Mediante el programa Audacity\textsuperscript{TM}, se grabaron treinta muestras
de diferentes personas, pronunciando desde palabras individuales, a frases más
elaboradas. Las mismas se almacenaron en el formato sin compresión WAV, con un
solo canal de audio (mono), y una frecuencia de muestreo de $8$ Khz.
\subsection{Obtención de la señal de los wav}
Para obtener la señal de los archivos se utilizó la función wavread de octave,
la cual dado un archivo de audio mono, retorna un vector con las diferentes
muestras.
\subsection{Transformada rápida de Fourier y truncado}
En base a la función fft de octave, se calculó la transformada rápida de
Fourier a cada archivo, obteniendo la señal en frecuencia a comprimir.
Debido a que la señal de audio de un wav es real, se pudo truncar el vector
obtenido de la fft, conservando solo la mitad más uno de los valores. Esto se
debe a que, si $X[n]$ es una función discreta tal que $X[n] \in
\mathbb{R}$, y llamando $N$ el número de muestras totales, entonces:
\begin{equation} \label{eq1}
    \begin{split}
        \hat{X}[k] & = \hat{X}[((-k))_N] \\
         & = \hat{X}[((N - k))_N] \\
         & = \hat{X}[N-k] \\
     \end{split}
\end{equation}
Donde se usa la notación $((a))_b$ para denotar $a$ módulo $b$.
Luego:
\begin{equation} \label{eq2}
    \begin{split}
        \hat{X}[k] & = \overline{\hat{X}[N-k]} \\
        %\hat{X}[\frac{N}{2}] & = \overline{\hat{X}[N-\frac{N}{2}]} \\
        \hat{X}[\frac{N}{2}+1] & = \overline{\hat{X}[N-\frac{N}{2}+1]} \\
     \end{split}
\end{equation}
\subsection{Eliminación de coeficientes próximos a cero (``thresholding'')}
Para cierto valor $\epsilon$ que se fue variando arbitrariamente, se reemplazó
los valores de $\hat{X}[k]$ tales que $|\hat{X}[k]| < \epsilon$, por cero. \\
Esto permitió reducir el tamaño final mejorando el proceso de compresión,
eliminando señales debiles que poco aportan al sonido en su totalidad.
\subsection{Cuantificación}
Cuantificar una señal implica asociar (``mappear'') el conjunto de valores de la
misma a uno menor. Esto, como es de esperarse, tiene la finalidad de
reducir el tamaño final del archivo comprimido. Existen varios métodos de
cuantificación, desde simples a otros más complejos que toman en cuenta la
capacidad humana para distinguir frecuencias muy similares, de forma de agrupar
estas bajo una misma y así reducir la información necesaria a almacenar sin una
pérdida de fidelidad significativa. En nuestro caso, hicimos uso de una
cuantificación lineal, donde el paso $\Delta$ de la misma se obtienen
mediante la fórmula:
$$\Delta = \left(\frac{M_{max} - M_{min}}{L}\right)$$
Siendo $M_{max}$ el máximo valor en el vector de señales, $M_{min}$ el mínimo,
y L el nivel de cuantificación deseado.
Estos tres valores deben ser almacenados en el archivo comprimido, ya que
aportan información necesaria para la descompresión (en otras palabras, se
requieren para revertir la codificación de Huffman, mencionada en la próxima
sección).
\subsection{Codificación de Huffman}
Finalmente se hace empleo de la codificación de Huffman, la cual asigna
secuencia de bits a cada valor, en base a la frecuencia con que aparece cada
uno. Es decir, aquellos valores con mayor frecuencia son asignados las
secuencias más cortas, codificando de manera eficiente la información y
reduciendo su tamaño.
Para nuestro caso particular, evitamos guardar los archivos codificados en si,
pero calculamos la codificación para saber cuanto ocuparía la versión final
comprimida.
\subsection{Reconstrucción de la señal}
Para reconstruir la señal original desde el archivo cuantificado, se aplica los
procesos inversos. En base a la propiedad mencionada anteriormente por la cual
se pudo descartar la mitad menos uno de los valores, se vuelve a generar los
faltantes, y al vector obtenido se le aplica la función inversa (ifft en
octave), que, utilizando la antitransformada de Fourier, se genera un archivo
de sonido descomprimido, similar al original (no idéntico, debido al descarte de
valores y aproximaciones). Notar que si efectivamente se realiza la
codificación de Huffman, se requieren los tres parámetros mencionados
previamente durante la cuantificación, para la decodificación.
\section{Resultados}
A continuación se presentan comparaciones de diferentes archivos de audio, con
su tamaño original, tamaño comprimido, razón de compresión, y distorción. Los cálculos fueron realizados tomando un $\epsilon = 0.1$ y $L = 4$
\begin{center}
    \begin{tabular}{c | c | c | c | c}
        \hline
        Archivo & Tamaño (bytes) & Tamaño comprimido (bytes) & Compresión (\%) &  Distorción \\ \hline
        p1.wav & 64700 & 7726 & 0.11941 & 9.4042e-04 \\
        p2.wav & 156684 & 21617 & 0.13797 & 8.6123e-05 \\
        p3.wav & 47404 & 6793 & 0.14328 & 2.6806e-04 \\
        p4.wav & 39468 & 5358 & 0.13574 & 2.8885e-05 \\
        p5.wav & 36644 & 4420 & 0.12062 & 1.8816e-04 \\
        p6.wav & 36644 & 4796 & 0.13086 & 6.1311e-04 \\
        p7.wav & 52748 & 5707 & 0.10818 & 7.0363e-04 \\
        p8.wav & 45428 & 6159 & 0.13556 & 3.1064e-04 \\
        p9.wav & 52748 & 5499 & 0.10424 & 7.9479e-04 \\
        p10.wav & 46892 & 4749 & 0.10127 & 1.0548e-03 \\
        p11.wav & 29532 & 3798 & 0.12859 & 1.5450e-03 \\
        p12.wav & 36638 & 4123 & 0.11252 & 1.9993e-04 \\
        p13.wav & 28280 & 3039 & 0.10744 & 7.5817e-04\\
        p14.wav & 31994 & 4433 & 0.13855 & 2.9970e-04\\
        p15.wav & 24564 & 2957 & 0.12034 & 2.8484e-04 \\
        p16.wav & 24750 & 3764 & 0.15205 & 4.0124e-04\\
        p17.wav & 23564 & 2611 & 0.11078 & 2.2699e-04\\
        p18.wav & 33132 & 4109 & 0.12400 & 2.0743e-04 \\
        p19.wav & 31580 & 3889 & 0.12314 & 3.7458e-04\\
        p20.wav & 44086 & 6243 & 0.14161 & 2.0671e-04\\
        p21.wav & 31994 & 4612 & 0.11534 & 2.0510e-04\\
        p22.wav & 35740 & 5858 & 0.16390 & 2.7977e-04\\
        p23.wav & 26428 & 4418 & 0.16714 & 4.5768e-04\\
        p24.wav & 24875 & 3589 & 0.14427 & 6.2918e-04\\
        p25.wav & 32636 & 4051 & 0.12411 & 7.1053e-04\\
        p26.wav & 26428 & 3104 & 0.11743 & 2.0185e-03\\
        p27.wav & 40396 & 4510 & 0.11164 & 9.7388e-04\\
        p28.wav & 40396 & 5795 & 0.14345 & 1.7631e-03\\
        p29.wav & 32636 & 5361 & 0.16425 & 4.5588e-04\\
        p30.wav & 32636 & 3716 & 0.11384 & 1.0736e-03\\
        \hline
    \end{tabular}
\end{center}

Como se puede observar, las compresiones más bajas rondan cerca de un $17\%$
del tamaño original, mientras que las más altas se aproximan a un $10\%$.
Además, las distorciones se hallan en ordenes de magnitud de $10^{-3}$ y hasta
$10^{-5}$. Esto resulta en ganancias significativas a la hora de almacenar los
datos, transmitirlos por canales lentos, o en situaciones que se requiera
tiempos de respuesta cercanos al tiempo real, como en aplicaciones de
videoconferencia o telefonía.

\includegraphics[scale=0.8]{compresion_media_fixed_bits.png}
\includegraphics[scale=0.8]{compresion_media_fixed_epsilon.png}
\includegraphics[scale=0.8]{distorcion_media_fixed_bits.png}
\includegraphics[scale=0.8]{distorcion_media_fixed_epsilon.png}
\includegraphics[scale=0.8]{signal_with_compression.png}
\includegraphics[scale=0.8]{signal_without_compression.png}
\section{Conclusiones}
La transformada rápida de Fourier resulta una buena introducción didáctica al
problema de compresión de señales, en parte debido a que utilizando funciones
de librería, uno puede evitar perderse en los detalles de implementación y
concentrarse en el asunto en cuestión. \\
A su vez, es claro cómo, la codificación de Huffman, siendo óptima para la
codificación de señales, resulta tan usada tanto en procesamiento de voz,
imagenes, y varios otros ambitos: las gananciasen tamaño logradas, en conjunto
con su relativamente sencillo planteo e implementación, lo tornan en una de las
elecciones principales. \\

Con respecto al proceso de cuantificación, este involucró identificar para
cada componente del vector de frecuencias, el nivel de cuantificación al que
pertenecía, de manera tal que en el vector cualificado se le asignara ese nivel
a la componente. Para hacer esto se utilizó dos bucles sencillos, donde se
iteraba sobre todas las componentes y para cada una, se volvía a iterar sobre
el vector con los niveles de cuantificación. La complejidad de este algoritmo
es $O(nm)$, donde $n$ es la cantidad de componentes del vector de frecuencias y
$m$ está dado por $2^{L}$. Como $n$ es usualmente un número bastante grande(En
nuestros ejemplos, al rededor de unas 30000 muestras), resultó que el algoritmo
tenía un tiempo de ejecución demasiado elevado. Por este motivo, se decidió
implementar la búsqueda del nivel de cuantificación utilizando búsqueda
binaria. A través de este nuevo algoritmo, se logró bajar la complejidad a
$O(n\log m)$, lo cual se tradujo en niveles aceptables de tiempos de ejecución.

En los archivos procesados que se obtienen como resultado de aplicar la
antitransformada a las frecuencias cuantificadas, puede notarse que hay una
reducción significativa del volumen precisamente en el medio de la
reproducción. Esta anomalía se da como resultado de la compresión. En el
siguiente gráfico puede notarse como las frecuencias con menor valor absoluto,
se encuentran aproximadamente en la mitad del rango de frecuencias.
Al eliminar las señales dbiles y cuantificarlas, la información de estas
frecuencias se pierde. Esto produce que ocurra la anomalía antes mencionada.
Para poder solucionar este problema, es necesario utilizar un nivel de
cuantificación lo suficientemente alto, como para no cancelar estas frecuencias
bajas.
\section{Bibliograf\'ia}
G. Rajesh, A. Kumar, K. Ranjeet. 2011. Speech Compression using Different Transform Techniques.
\end{document}

